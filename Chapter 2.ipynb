{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "## 2.3 Empirical Risk Minimization with Inductive Bias\n",
    "\n",
    "### Motivation\n",
    "ERM might lead to overfitting. A solution is to apply the ERM learning rule over a restricted search space. We choose set of predictors (a prior) before seeing the data. This set is called a hypothesis class, $\\mathcal{H}$.\n",
    "\n",
    "By choosing a predictor from $\\mathcal{H}$, we bias it toward a particular set of predictors. This is known as an **inductive bias**.\n",
    "\n",
    "### What kind of restrictions to impose?\n",
    "A simple restriction to impose is an upper bound on the size of $\\mathcal{H}$.\n",
    "\n",
    "#### Finite Hypothesis Classes are PAC learnable\n",
    "\n",
    "We have data $\\mathcal{X}$, labels $\\mathcal{Y}$ forming a sample $\\mathcal{S}$ of size $m$. From our hypothesis class, we want to pick a hypothesis which minimises our empirical loss:\n",
    "$$\n",
    "h_S \\in \\text{argmin}\\ L_S (h)\n",
    "$$\n",
    "\n",
    "In this chapter, we make *the realizability assumption*:\n",
    "\n",
    "#### Definition 2.1\n",
    "> There exists hypotheses in the hypothesis class such that the true loss of such a hypothesis with respect to the true distribution of data and labels is equal to zero. Formally:\n",
    "$$\n",
    "L_{(D,\\ f)} (h^*) = 0\n",
    "$$\n",
    "> In other words, with probability 1 over random samples, $S$, where the instances of $S$ are sampled according to $D$ and labeled by $f$, we have $L_S(h^*) = 0$.\n",
    "\n",
    "Our algorithm only has access to the sample $S$, but we wish to bound the error with respect to the true distribution. This implies that our bound should depend on the relationship between $D$ and $S$. The common assumption made is that the training sample is generated by sampling points from the distribution independently of each other.\n",
    "\n",
    "#### I.I.D. Assumption\n",
    "> The examples in the training set are independently and identically distributed according to the distribution $D$. We denote this assumption by $S \\sim D^m$, where $D^m$ is the probability over $m$-tuples induced by applying $D$ to pick each element of the tuple independently of the other members of the tuple.\n",
    "\n",
    "Now, the true loss depends on the training set, $S$, which is picked by a random process. Thus, there is randomness in how we pick the predictor $h_S$. There is always some chance that we pick a bad sample which is not representative of $D$. Thus, instead of looking at getting 100% accuracy (for example), we look at how **probable** is getting 100% accuracy. (This is the \"probably\" part of PAC). Let $\\delta$ be the probability of getting a nonrepresentative sample. Then $(1-\\delta)$ is the *confidence parameter* of our prediction.\n",
    "\n",
    "Additionally, since we cannot guarantee 100% accuracy, we introduce the *accuracy parameter*, $\\epsilon$. (This is the \"approximately\" part of PAC). If our true loss (a.k.a. risk) is greater than $\\epsilon$, this is considered \"failure\" for the learner. On the other hand, if the true loss is $\\le \\epsilon$, then $h_S$ is an **approximately** correct predictor.\n",
    "\n",
    "Our goal is therefore to upper bound the probability to sample $m$-tuple of instances that will lead to failure of the learner.\n",
    "\n",
    "Formally, we want to bound:\n",
    "\n",
    "$$ D^m(\\{S: L_{(D, f)} (h_S) > \\epsilon\\}) (\\ast) $$\n",
    "> where $\\{S: L_{(D, f)} (h_S) > \\epsilon\\}$ is the set of samples where the true loss is greater than $\\epsilon$.\n",
    "\n",
    "Now let $\\mathcal{H}_B$ be the set of \"bad\" hypotheses, that is, these hypotheses lead to true loss greater than $\\epsilon$.\n",
    "\n",
    "Let $M$ be the set of misleading samples, which are samples which lead to empirical loss of 0 by some hypothesis $h_B$ which is actually contained in the set of \"bad\" hypotheses.\n",
    "\n",
    "Since we are minimising the empirical loss, and bounding the true error, we are looking at: $L_{(D, f)} (h_S) > \\epsilon$ and $L_S(h)=0$, which is exactly that our sample is in the set of misleading samples.\n",
    "\n",
    "Rewrite $M = \\bigcup_{h\\in \\mathcal{H}_B} \\{S: L_S(h) = 0\\}$.\n",
    "\n",
    "From ($\\ast$):\n",
    "$D^m(\\{S: L_{(D, f)} (h_S) > \\epsilon\\}) \\le D^m(M) = D^m(\\bigcup_{h\\in \\mathcal{H}_B} \\{S: L_S(h) = 0\\})$\n",
    "where the first inequality is due to the fact that the samples we are looking for are a subset of $M$.\n",
    "\n",
    "Now we use the *union bound* to upper bound the RHS.\n",
    "\n",
    "#### Lemma 2.2 (Union Bound)\n",
    "> For any 2 sets $A, B$ and a distribution $D, D(A \\cup B) \\le D(A) + D(B)$\n",
    "\n",
    "Let $ X= \\{S: L_{(D, f)} (h_S) > \\epsilon\\}$.\n",
    "\n",
    "$D^m(X) \\le \\sum_{h \\in \\mathcal{H}_B}  D^m(\\{S: L_S(h) = 0\\}) = \\sum_{h \\in \\mathcal{H}_B} Y$\n",
    "\n",
    "Now consider one term within the summation on the RHS. Suppose we have a bad hypothesis, $h$ from $\\mathcal{H}_B$. To achieve perfect accuracy is, $\\forall_i, h(x_i) = f(x_i)$. Since the samples are i.i.d, $Y = \\prod_i^m D(\\{x_i: h(x_i) = f(x_i)\\})$.\n",
    "\n",
    "For each individual sampling, $D(\\{x_i: h(x_i) = f(x_i)\\}) = 1 - L_{(D, f)} (h) \\le 1 - \\epsilon$, where the last equality follows because $h$ is a bad hypothesis.\n",
    "\n",
    "Merging our results and using the inequality $1- \\epsilon \\le e^{-\\epsilon}$, for each summation term, $Y$, $Y \\le (1-\\epsilon)^m \\le e^{-\\epsilon m}$.\n",
    "\n",
    "Now consider the entire summation: $D^m(X) \\le |\\mathcal{H}_B|e^{-\\epsilon m}$.\n",
    "\n",
    "Finally,\n",
    "\n",
    "#### Corollary 2.3\n",
    "> Let $\\mathcal{H}$ be a finite hypothesis class, $\\delta \\in (0,1)$ and $\\epsilon > 0$, \n",
    "> and $m$ be an integer that satisfies\n",
    "$$\n",
    " m \\ge \\frac{\\log(|\\mathcal{H}|/\\delta)}{\\epsilon}\n",
    "$$\n",
    "> Then, for any labeling function and for any distribution for which the realizability assumption holds,\n",
    "> it is true that: with probability of at least $1-\\delta$, for some i.i.d. sample $S$ of size $m$,\n",
    "> for every ERM hypothesis $h_S$, the true error is bounded by $\\epsilon$.\n",
    "\n",
    "Basically, for a sufficiently large $m$, the ERM rule over a finite hypothesis class will be probably approximately correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
